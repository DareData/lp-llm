{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ADVANCED CUSTOMIZATION OPTIONS - METHODS - EXAMPLES\n"
      ],
      "metadata": {
        "id": "JPcroE5WFj5y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Custom Token Parsing (with SentenceWindowParser):\n",
        "\n",
        "Enables parsing and segmenting long documents into manageable chunks based on sentence boundaries. This is useful for processing large texts where maintaining context over long distances can be challenging. By splitting text into smaller windows (that contain a fixed number of sentences), you can ensure that the context remains coherent during retrieval and processing.\n",
        "\n",
        "> Example:\n"
      ],
      "metadata": {
        "id": "ZERek8yMFnhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q llama_index"
      ],
      "metadata": {
        "id": "nV2ChZLVp8Xc"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex, Document\n",
        "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
        "from llama_index.core.postprocessor import MetadataReplacementPostProcessor"
      ],
      "metadata": {
        "id": "4ws6MVKJCeEI"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a sample text\n",
        "sample_text = \"\"\"\n",
        "Artificial intelligence (AI) is the simulation of human intelligence in machines.\n",
        "Machine learning (ML) is a subset of AI, which enables systems to automatically learn and improve from experience.\n",
        "Natural language processing (NLP) allows machines to understand and interpret human language.\n",
        "Deep learning (DL), a subset of ML, uses neural networks to model complex patterns in data.\n",
        "\"\"\"\n",
        "\n",
        "# Convert sample text to llamaindex's document structure\n",
        "documents = [Document(text=sample_text)]\n",
        "\n",
        "# Create the sentence window parser\n",
        "node_parser = SentenceWindowNodeParser.from_defaults(\n",
        "    window_size=3,  # we chose a window size of 3 sentences\n",
        "    window_metadata_key=\"window\",\n",
        "    original_text_metadata_key=\"original_text\",\n",
        ")\n",
        "\n",
        "# Extract the set of nodes that will be stored in the vectorindex (parsing)\n",
        "nodes = node_parser.get_nodes_from_documents(documents)\n",
        "\n",
        "# Build the vector index from the parsed nodes\n",
        "index = VectorStoreIndex(nodes)\n",
        "\n",
        "# Create a query engine with post-processing for metadata replacement\n",
        "# (replace the sentence in each node with it's surrounding context)\n",
        "query_engine = index.as_query_engine(\n",
        "    similarity_top_k=2,\n",
        "    node_postprocessors=[\n",
        "        MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Run a query and show the answer\n",
        "question = \"What is artificial intelligence?\"\n",
        "window_response = query_engine.query(question)\n",
        "print(window_response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TReBQx0IHvC",
        "outputId": "b55cd027-072e-4a0c-dfb8-55dc9e4a6f26"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artificial intelligence is the simulation of human intelligence in machines.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Custom Retrieval Configurations (using Retriever with Metadata filter):\n",
        "\n",
        "Allows adjusting how documents are retrieved from an index based on specific criteria. By using a metadata filter with a retriever, you can focus on retrieving only those documents that match certain metadata conditions (e.g., author, date, type). This helps to improve the relevance of the results returned by your queries, ensuring that only the most relevant data is fetched and improving the efficiency and accuracy of your LLM interactions.\n",
        "\n",
        "> Example:"
      ],
      "metadata": {
        "id": "IL1MQV_KGNXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q llama-index llama-index-vector-stores-chroma"
      ],
      "metadata": {
        "id": "_BQ0AXoJw-z-"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
        "import chromadb\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "from llama_index.core.schema import Node"
      ],
      "metadata": {
        "id": "yMGheLUrw5_j"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your API key\n",
        "import openai\n",
        "openai.api_key = \"<YOUR_API_KEY>\""
      ],
      "metadata": {
        "id": "gueWIxd1luOY"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the directory and download the pdfs from the internet\n",
        "!mkdir documents\n",
        "!wget https://wwfint.awsassets.panda.org/downloads/wwf_impacts_of_plastic_pollution_on_biodiversity.pdf -O ./documents/file1.pdf\n",
        "!wget https://www.thegef.org/sites/default/files/publications/STAP_MarineDebris_-_website_1.pdf -O ./documents/file2.pdf\n",
        "\n",
        "# Load the documents\n",
        "documents = SimpleDirectoryReader(input_dir=\"./documents\").load_data()\n",
        "\n",
        "# Metadata mapping for each file\n",
        "metadata_map = {\n",
        "    \"file1.pdf\": {\n",
        "        \"author\": \"Mine B. Tekman\",\n",
        "        \"document_type\": \"Summary of a study for wwf\",\n",
        "        \"publication_year\": \"2022\",\n",
        "    },\n",
        "    \"file2.pdf\": {\n",
        "        \"author\": \"Richard C. Thompson\",\n",
        "        \"document_type\": \"Scientific information paper\",\n",
        "        \"publication_year\": \"2011\",\n",
        "    }\n",
        "}\n",
        "\n",
        "# Add the metadata to documents based on file names\n",
        "for doc in documents:\n",
        "    file_name = doc.extra_info['file_path'].split(\"/\")[-1] # Extract file name from the path\n",
        "    if file_name in metadata_map:\n",
        "        doc.metadata = metadata_map[file_name]\n",
        "\n",
        "# Create a vector store and embedding model\n",
        "client = chromadb.PersistentClient(path=\"./metadata_filtered_db\")\n",
        "collection = client.get_or_create_collection(\"multi_doc_collection\")\n",
        "vector_store = ChromaVectorStore(chroma_collection=collection)\n",
        "embedding_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3o23gN6bmVfm",
        "outputId": "71ada6f7-51e2-4428-f37e-604e524d4169"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘documents’: File exists\n",
            "--2024-11-19 18:25:46--  https://wwfint.awsassets.panda.org/downloads/wwf_impacts_of_plastic_pollution_on_biodiversity.pdf\n",
            "Resolving wwfint.awsassets.panda.org (wwfint.awsassets.panda.org)... 13.224.14.117, 13.224.14.85, 13.224.14.76, ...\n",
            "Connecting to wwfint.awsassets.panda.org (wwfint.awsassets.panda.org)|13.224.14.117|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4323968 (4.1M) [application/pdf]\n",
            "Saving to: ‘./documents/file1.pdf’\n",
            "\n",
            "./documents/file1.p 100%[===================>]   4.12M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-11-19 18:25:46 (42.3 MB/s) - ‘./documents/file1.pdf’ saved [4323968/4323968]\n",
            "\n",
            "--2024-11-19 18:25:46--  https://www.thegef.org/sites/default/files/publications/STAP_MarineDebris_-_website_1.pdf\n",
            "Resolving www.thegef.org (www.thegef.org)... 23.185.0.1, 2620:12a:8001::1, 2620:12a:8000::1\n",
            "Connecting to www.thegef.org (www.thegef.org)|23.185.0.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4766030 (4.5M) [application/pdf]\n",
            "Saving to: ‘./documents/file2.pdf’\n",
            "\n",
            "./documents/file2.p 100%[===================>]   4.54M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2024-11-19 18:25:47 (65.0 MB/s) - ‘./documents/file2.pdf’ saved [4766030/4766030]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the index\n",
        "index = VectorStoreIndex.from_documents(documents, embedding_model=embedding_model, vector_store=vector_store)\n",
        "\n",
        "# Define a metadata filter function\n",
        "def metadata_filter(node: Node):\n",
        "   # Filter by publication year\n",
        "    return int(node.metadata.get(\"publication_year\", 0)) == 2022\n",
        "\n",
        "# Create a retriever with the metadata filter\n",
        "retriever = index.as_retriever(\n",
        "    similarity_top_k=1,\n",
        "    filter_fn=metadata_filter\n",
        ")\n",
        "\n",
        "# Query the index\n",
        "query_engine = RetrieverQueryEngine.from_args(\n",
        "    retriever=retriever,\n",
        "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
        ")"
      ],
      "metadata": {
        "id": "9WV7PFbih7Vm"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can try to change the publication year to 2011 (the publication year of the second file), then run the same query and check the differences between the two answers."
      ],
      "metadata": {
        "id": "pgiYw028pnFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run a query\n",
        "query = \"Why do we have to give importance to the oceans when talking about global enviromental problems?\"\n",
        "response = query_engine.query(query)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjJu7SrIorqm",
        "outputId": "b23d8e88-a998-4d83-d252-3c8539e2d66f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oceans are crucial to global ecological services and play a significant role in maintaining the balance of the Earth's ecosystems. They are highly sensitive environments that provide essential services such as regulating the climate, supporting biodiversity, and producing oxygen. Therefore, addressing issues like marine debris in the oceans is important as it directly impacts the health of these vital ecosystems and the overall well-being of the planet.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Flare:\n",
        "\n",
        "Flare is a method designed to enhance the retrieval process by providing a more dynamic and context-aware interaction with the data. It adapts to the user's query by focusing on the most relevant portions of the document and offering refined suggestions, leading to more accurate and contextually appropriate responses. This whole process helps to reduce hallucinations.\n",
        "\n",
        "> Example:"
      ],
      "metadata": {
        "id": "uiXW5jGQGSIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q llama-index"
      ],
      "metadata": {
        "id": "bsfQ9eZzfEnw"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex, Document\n",
        "from llama_index.core.node_parser import SimpleNodeParser\n",
        "from llama_index.core.query_engine import FLAREInstructQueryEngine"
      ],
      "metadata": {
        "id": "eqqCP5TbEaN1"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your API key\n",
        "import openai\n",
        "openai.api_key = \"<YOUR_API_KEY>\""
      ],
      "metadata": {
        "id": "F8bQ6cGhgiX5"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the sample text to be indexed\n",
        "sample_text = \"\"\"\n",
        "Artificial intelligence (AI) is the simulation of human intelligence in machines.\n",
        "Machine learning (ML) is a subset of AI, which enables systems to automatically learn and improve from experience.\n",
        "Natural language processing (NLP) allows machines to understand and interpret human language.\n",
        "Deep learning (DL), a subset of ML, uses neural networks to model complex patterns in data.\n",
        "\"\"\"\n",
        "\n",
        "# Create a list of Document objects (each document is treated as separate text data)\n",
        "documents = [Document(text=sample_text)]\n",
        "\n",
        "# Initialize a simple node parser to parse the document into nodes and parse the documents into nodes\n",
        "node_parser = SimpleNodeParser.from_defaults()\n",
        "nodes = node_parser.get_nodes_from_documents(documents)\n",
        "\n",
        "# Build the vector index from the parsed nodes\n",
        "vector_index = VectorStoreIndex(nodes)\n",
        "\n",
        "# Create a simple query engine based on the vector index\n",
        "index_query_engine = vector_index.as_query_engine()\n",
        "\n",
        "# Set up the FLARE query engine\n",
        "flare_query_engine = FLAREInstructQueryEngine(\n",
        "    query_engine=index_query_engine,\n",
        "    max_iterations=4,  # Maximum number of reasoning iterations\n",
        "    verbose=True,  # Enables detailed output to understand the reasoning steps\n",
        ")"
      ],
      "metadata": {
        "id": "Bl_hOAqke_Vt"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run a query\n",
        "question = \"What is the relationship between artificial intelligence and machine learning?\"\n",
        "response = flare_query_engine.query(question)\n",
        "\n",
        "# Print the result\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzPUUnknquyv",
        "outputId": "de0aa3ce-87af-425e-e796-e49e7c54460b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;3;32mQuery: What is the relationship between artificial intelligence and machine learning?\n",
            "\u001b[0m\u001b[1;3;34mCurrent response: \n",
            "\u001b[0m\u001b[1;3;38;5;200mLookahead response: [Search(What is the relationship between artificial intelligence and machine learning?)]\n",
            "\u001b[0m\u001b[1;3;38;5;200mUpdated lookahead response: Machine learning is a subset of artificial intelligence, enabling systems to automatically learn and improve from experience.\n",
            "\u001b[0m\u001b[1;3;34mCurrent response:  Machine learning is a subset of artificial intelligence, enabling systems to automatically learn and improve from experience.\n",
            "\u001b[0m\u001b[1;3;38;5;200mLookahead response: [Search(How do artificial intelligence and machine learning differ?)]\n",
            "\u001b[0m\u001b[1;3;38;5;200mUpdated lookahead response: Artificial intelligence encompasses a broader scope of simulating human intelligence in machines, while machine learning is a specific subset of AI that focuses on enabling systems to learn and improve from experience automatically.\n",
            "\u001b[0m\u001b[1;3;34mCurrent response: Machine learning is a subset of artificial intelligence, enabling systems to automatically learn and improve from experience. Artificial intelligence encompasses a broader scope of simulating human intelligence in machines, while machine learning is a specific subset of AI that focuses on enabling systems to learn and improve from experience automatically.\n",
            "\u001b[0m\u001b[1;3;38;5;200mLookahead response: [Search(How does machine learning relate to artificial intelligence?)]\n",
            "\u001b[0m\u001b[1;3;38;5;200mUpdated lookahead response: Machine learning is a subset of artificial intelligence that enables systems to automatically learn and improve from experience.\n",
            "\u001b[0m\u001b[1;3;34mCurrent response: Machine learning is a subset of artificial intelligence, enabling systems to automatically learn and improve from experience. Artificial intelligence encompasses a broader scope of simulating human intelligence in machines, while machine learning is a specific subset of AI that focuses on enabling systems to learn and improve from experience automatically. Machine learning is a subset of artificial intelligence that enables systems to automatically learn and improve from experience.\n",
            "\u001b[0m\u001b[1;3;38;5;200mLookahead response: [Search(How do artificial intelligence and machine learning relate to each other?)]\n",
            "\u001b[0m\u001b[1;3;38;5;200mUpdated lookahead response: Machine learning is a subset of artificial intelligence that enables systems to automatically learn and improve from experience.\n",
            "\u001b[0mMachine learning is a subset of artificial intelligence, enabling systems to automatically learn and improve from experience. Artificial intelligence encompasses a broader scope of simulating human intelligence in machines, while machine learning is a specific subset of AI that focuses on enabling systems to learn and improve from experience automatically. Machine learning is a subset of artificial intelligence that enables systems to automatically learn and improve from experience. Machine learning is a subset of artificial intelligence that enables systems to automatically learn and improve from experience.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Raptor:\n",
        "\n",
        "Raptor is another advanced technique in LlamaIndex designed for building solid RAG applications in production. This model is based on constructing a tree structure that encapsulates both granular details and overarching narratives. Raptor applies optimized algorithms to integrate information across extensive documents at varying abstraction levels, significantly enhancing question-answering tasks, particularly those requiring multi-step reasoning.\n",
        "\n",
        "> Example:\n"
      ],
      "metadata": {
        "id": "FPNsleE3GWhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q llama-index llama-index-packs-raptor llama-index-vector-stores-chroma"
      ],
      "metadata": {
        "id": "pAANjDwnqJCS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeca15ea-8a22-47db-c821-4be5be233230"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/88.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/56.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
        "from llama_index.core import VectorStoreIndex\n",
        "import chromadb\n"
      ],
      "metadata": {
        "id": "-qf070MCEtbu"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using !wget to download the document from the internet\n",
        "# (we chose a random file about \"fruit and vegetable production in the Federated States of Micronesia\")\n",
        "!wget https://openknowledge.fao.org/server/api/core/bitstreams/aac462ae-90d2-422c-b9e6-3e5336b18b52/content -O ./crop_production_and_cultivation_document.pdf\n",
        "\n",
        "# Load the document\n",
        "documents = SimpleDirectoryReader(input_files=[\"./crop_production_and_cultivation_document.pdf\"]).load_data()\n",
        "\n",
        "# Setup the vector store and embeddings\n",
        "client = chromadb.PersistentClient(path=\"./crop_production_and_cultivation_db\")\n",
        "collection = client.get_or_create_collection(\"crop_production_and_cultivation\")\n",
        "vector_store = ChromaVectorStore(chroma_collection=collection)\n",
        "\n",
        "embedding_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")\n",
        "llm_model = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
        "\n",
        "# Create an index with the documents\n",
        "index = VectorStoreIndex.from_documents(documents, embedding_model=embedding_model, vector_store=vector_store)\n",
        "\n",
        "# Create a query engine from the index\n",
        "query_engine = index.as_query_engine()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TEyrBDPtVFO",
        "outputId": "88cded9b-ced6-46ec-87ee-057324790666"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-19 18:30:54--  https://openknowledge.fao.org/server/api/core/bitstreams/aac462ae-90d2-422c-b9e6-3e5336b18b52/content\n",
            "Resolving openknowledge.fao.org (openknowledge.fao.org)... 3.232.251.16\n",
            "Connecting to openknowledge.fao.org (openknowledge.fao.org)|3.232.251.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 200\n",
            "Length: unspecified [application/pdf]\n",
            "Saving to: ‘./crop_production_and_cultivation_document.pdf’\n",
            "\n",
            "./crop_production_a     [   <=>              ]   3.84M  7.55MB/s    in 0.5s    \n",
            "\n",
            "2024-11-19 18:30:55 (7.55 MB/s) - ‘./crop_production_and_cultivation_document.pdf’ saved [4029979]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run a query\n",
        "query = \"What are the best practices for fruit and vegetable production and cultivation?\"\n",
        "response = query_engine.query(query)\n",
        "\n",
        "# Show the answer\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjxkbS1Zq2Yl",
        "outputId": "466bb764-8dc0-4791-861e-07fffed84caa"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sunlight, good soil, water source, and wind shelter are crucial factors for successful fruit and vegetable production. It is important to ensure that plants receive at least six hours of sunlight daily, have access to good soil that can be improved with minerals and manure if needed, are located near a water source but not in areas prone to waterlogging, and are protected from strong winds. When choosing crops to plant, consider factors like ease of growth, suitability for the local region, and maximizing space efficiency. Opt for vegetables that are easy to grow such as Chinese cabbage, tomatoes, squash, lettuce, and root vegetables like taro. Additionally, it is beneficial to grow crops that are commonly grown in the local area to receive support and guidance from experienced farmers.\n"
          ]
        }
      ]
    }
  ]
}