## INDEXATION AND INGESTION 🍽️

Effective data ingestion and indexation are crucial to building robust LLM applications, especially for developing Retrieval-Augmented Generation (RAG) systems. These processes are the key points of scalable and efficient solutions, enabling the different models to retrieve and process the most relevant information from large amounts of data.

> Note: while there are many approaches to data ingestion and indexing, in a lot of use-cases, simpler methods can be highly effective. That is why some of the tools that we explain here are relatively basic.

In this module, we will learn about:
1. [LlamaIndex](01-LlamaIndex.md): one of the main frameworks for pre- and post-processing text data. It offers a lot of integrations with different data formats and introduces innovative approaches to enhance typical ingestion processes.
In this section, we'll explore how LLamaIndex can significantly impact the development LLM applications. We'll also explore practical examples that show the the use of LlamaIndex and its techniques.

2. [LangChain](02-LangChain-ingestion.md): known for its simplicity, provides a very basic ingestion system suitable for many projects. Despite its straightforward nature, LangChain is a powerful tool for chaining together data processing steps and integrating with other components of LLM applications.

3. [Vector Databases](03-VectorStores.md): the most sophisticated system in this section, use advance mathematical methods to efficiently handle large amounts of data.

By the end of this module, you will have a solid understanding of these tools and how to apply them to build scalable, efficient LLM-based systems. Whether you need a simple solution or a more advanced approach, you'll be equipped to choose the right tools for your specific use case.
