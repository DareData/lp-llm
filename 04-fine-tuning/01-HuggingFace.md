# HuggingFace ðŸ¤—

After introducing the concept of fine-tuning and exploring some of the techniques avaliable, we want to show you the main ecosystem used for fine-tuning your projects: **HUGGING FACE**.

Hugging Face is a company known for its work in the field of artificial intelligence, particularly in natural language processing (NLP). They are widely recognized for their open-source library called "Transformers," which provides a large collection of pre-trained models for various NLP tasks such as text classification, information extraction, question answering, and more.

The "Transformers" library is built to be highly accessible and flexible, allowing developers and researchers to experiment with state-of-the-art models like BERT, GPT, T5, and others. These models can understand, generate, and translate human language, making them valuable for a wide range of applications.

Hugging Face offers streamlined workflows for fine-tuning. Through their libraries and integrations, you can easily load pre-trained models and fine-tune them on specific datasets. The platform supports several techniques for efficient fine-tuning, some of them mentioned in this learning pod, such as Low-Rank Adaptation (LoRA) and Parameter-Efficient Fine-Tuning (PEFT).

Hugging Face also offers a collaborative platform where the AI community can share models, contribute to model development, and access tools for training and deploying AI models. This collaborative aspect has been instrumental in democratizing access to cutting-edge AI technologies and fostering innovation in the field.

The following video explains how integrate Hugging Face and Langchain to access and implement pre-trained models for building AI applications in natural language processing.

<img src="../images/_j7JEDWuqLEhd.jpg" alt="" width="300" height="auto">

[Link to video](https://www.youtube.com/watch?v=_j7JEDWuqLE)
