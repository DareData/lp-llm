# Welcome to LLM basics

There are several steps to constructing a Large Language Model. From understanding what a Neural Network (NN) is, the basic building blocks, towards grasping the complex concept of a Transformer.
In this first chapter of this learning pod, we will describe and explain all the essential concepts that make Large Language Models (LLMs) possible.
By the end of this 00 section, you should know about:
- what a NN is and how perceptrons work as its basic units structures
- how does a NN learn, incluiding the backpropagation rule
- activation functions and their roles
- tokens and embedding architectures
- the Transformer architecture and its mechanisms
  
This LLM introduction aims to set the stage for a deeper exploration of these fundamental concepts. Trying to introduce each topic in a way that builds excitement and curiosity, encouraging you to dive into the details of the workflow of Large Language Models.
